# Development Roadmap

## Phase 1: The "Manual" Pod & Watchdog
- [ ] Select a base LLM and configure the deployment environment.
- [ ] Implement an internal **Watchdog Service** to monitor API activity and trigger self-termination after timeout.
- [ ] Deploy the model with a public URL (OpenAI-compatible API).

## Phase 2: Orchestration (Control App)
- [ ] TBD: Create a lightweight control interface (e.g., Telegram bot) to start/stop instances.

## Phase 3: Expansion
- [ ] Support for Audio and Image generation models.
